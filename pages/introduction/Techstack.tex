\raggedbottom
In this chapter, we will delve into the inner workings of the ExpoSE framework, what tools it uses and their function within. 
For the following sections, we will use the code snippet \autoref{lst:expose-sample-program} to explain how the system works. 


\begin{lstlisting}[language=JavaScript,float, caption={A simple program for ExpoSE}, label={lst:expose-sample-program}]
const S$ = require("S$");


let x = S$.symbol("value"); 
let y = S$.symbol("multiplier", 2);

if (x > 0) {
    S$.assert(x*y > x, "assertion violation"); 
}


\end{lstlisting}




\section{Jalangi2}
\label{sec:jalangi}
\textbf{Jalangi2} \cite{noauthor_samsungjalangi2_nodate} is a framework for creating dynamic analyses for JavaScript, and was first presented by \citet{sen_jalangi_2013}. It is used to instrument the JavaScript code that is to be analysed and provides callbacks for a program to spy into the execution and shadow the variables.
Jalangi2 enables this by breaking each execution statement down into atomic units, which are made up of the functions listed \autoref{tab:jal-fun}, which in turn provide callbacks to hook further into the execution.
The analysing tool can implement these callbacks in order to gain insight and/or modify the return value.


To instrument the code snippet in \autoref{lst:expose-sample-program}, Jalangi2 first transforms the passed code to ES6 using Babel\footnote{https://babeljs.io/}, to ensure a consistent syntax. 
Afterward, Jalangi2 instruments the code using the JavaScript parser "acorn"\footnote{https://github.com/acornjs/acorn} to generate the AST (Abstract Syntax Tree) and then rewrites the code using Jalangi's own operations. This creates two files per input: 
A \lstinline+{filename}_jalangi.js+ and a \lstinline+{filename}_jalangi.json+. The .js file, contains the instrumented code, similar to \autoref{lst:code-snippet}, along with the static unique instruction identifiers (iids) of each callback as a JSON object, while the .json file only contains the iids.

Although the functions exhibit variation in their parameters, they always include the iid (instruction identifier) as their primary parameter. This identifier serves as a unique reference within a JSON object, which stores an array for each statement. Each array contains critical metadata consisting of the starting line number, the column of the expression on that line, the line number where the expression concludes, and the respective column number associated with the termination of the expression.



\begin{lstlisting}[float, language=JavaScript, caption={[Instrumented program snippet]Lines 1 and 4 of the program snippet \autoref{lst:expose-sample-program}, instrumented by Jalangi2, with explanation}, label={lst:code-snippet}]
J$.N(225, 'S$', S$, 0);             // Init S$
J$.N(233, 'x', x, 0);               // Init x
J$.N(241, 'y', y, 0);               // Init y
var S$ = J$.X1(41,                  // Top level declaration
    J$.W(33, 'S$',                  // Write the result of the following:
        J$.F(25,              // Call the function with the follwing parameter:
            J$.R(9, 'require', require, 2),// Read the value of "require"
            0)  (
                J$.T(17, "S$", 21, false)    // Retrieve the value of S$
                ), S$, 3));
var x = J$.X1(89,                            // Top level declaration
    J$.W(81, 'x',                            // Write the result of the following:
        J$.M(73,                                   // Call the function of:
            J$.R(49, 'S$', S$, 1),           // Read the value of the expression S$
            'symbol', 0)                     // Name of the called function
                (J$.T(57,"value", 21, false),// Defines the value of the 
                                             // variable as literal
        J$.T(65, 0, 22, false)),x, 3));      // Retrieve the value "0"
\end{lstlisting}
Every assignment can be traced on a granular level, enabling the analyser to know the exact state of a program, at any stage of the execution, as depicted in \autoref{lst:code-snippet}. If, for example, we wanted to modify, or simply log the value of the variable “x” in line 11, we could do so by hooking into the callback function provided for the function T in line 16 (accessing the execution process).
This example, of course, is almost as simple as it can get. This is because JavaScript is known for having expressions that contain multiple callbacks, which in turn may or may not have callbacks themselves, colloquially called “Callback Hell” \cite{max_ogden_callback_2019}. And while an example with a callback would be a better representation of a real program, it would also mean that the instrumented code example be exponentially larger, rendering the example impractical (not to mention, \textit{rendering} it on PDF while ensuring its legibility). \\


\begin{table}[t]
\resizebox{\linewidth}{!}{%
	\begin{tabular}{l|l|l}
    {\lstinline|J$.U           |} & Unary operation                                       & {\lstinline|unaryPre|} and {\lstinline|unary|}                      \\
		{\lstinline|J\$.B           |} & Binary operation                                      & \lstinline|binaryPre| and \lstinline|binary|                    \\
		{\lstinline|J\$.C           |} & Condition                                             & \lstinline|conditional|                             \\
		{\lstinline|J\$.C1          |} & Switch key \lstinline|x in switch(x) { ... }|                    & no callback                             \\
    {\lstinline|J\$.C2          |} & case label \lstinline|C1 === C2|                                  & no own callback, uses callback of {\lstinline|J\$.C|} \\
		{\lstinline|J\$.\_          |} & Last value passed to C                                & no own callback                         \\
    {\lstinline|J\$.H           |} & hash in for-in. Wrap object \lstinline|o in for (x in o) { ... }| & {\lstinline|forinObject|}                             \\
  {\lstinline|J\$.I           |} & Ignore argument (Identity)                             & no callback                             \\
		{\lstinline|J\$.G           |} & Get a field                                              & \lstinline|getFieldPre| and \lstinline|getField|                \\
		{\lstinline|J\$.P           |} & Put a Field                                             & \lstinline|putFieldPre| and \lstinline|putField|                \\
		{\lstinline|J\$.R           |} & Read variable                                         & \lstinline|read|                                    \\
		{\lstinline|J\$.W           |} & Write variable                                        &\lstinline|write |                                  \\
		{\lstinline|J\$.N           |} & Init                                                  &\lstinline|declare|                                 \\
		{\lstinline|J\$.T           |} & object/function/regexp/array Literal                  &\lstinline|literal |                                \\
		{\lstinline|J\$.F           |} & Function call                                         &\lstinline|invokeFun|                               \\
    {\lstinline|J\$.M           |} & Method call                                           &\lstinline|invokeFun| and uses callbacks of {\lstinline|J\$.P|}   \\
		{\lstinline|J\$.A           |} & Modify and assign \lstinline|+=, -= ...|                          & uses callbacks of \lstinline|J\$.P| and \lstinline|J\$.B|       \\
		{\lstinline|J\$.Fe          |} & Function enter                                        &\lstinline| functionEnter |                          \\
		{\lstinline|J\$.Fr          |} & Function return                                       &\lstinline| functionExit  |                          \\
		{\lstinline|J\$.Se          |} & Script enter                                          &\lstinline| scriptEnter   |                          \\
		{\lstinline|J\$.Sr          |} & Script return                                         &\lstinline| scriptExit    |                          \\
		{\lstinline|J\$.Rt          |} & returned value                                        &\lstinline| \_return      |                          \\
		{\lstinline|J\$.Th          |} & thrown value                                          &\lstinline| \_throw       |                          \\
		{\lstinline|J\$.Ra          |} & Reads the return value stored by call to \lstinline|Rt()|         & no callback                             \\
		{\lstinline|J\$.Ex          |} & Uncaught exceptions                                   & no callback                             \\
		{\lstinline|J\$.L           |} & Returns the last computed value                       & no callback                             \\
		{\lstinline|J\$.X1          |} & top level expression                                  &\lstinline| endExpression               |            \\
		{\lstinline|J\$.Wi          |} & with statement                                        &\lstinline| \_with                      |            \\
		{\lstinline|J\$.endExecution|} & terminating execution                                 &\lstinline| endExecution                |            \\
		{\lstinline|J\$.S           |} & with statement                                        &\lstinline| runInstrumentedFunctionBody |            \\
	\end{tabular}}
	\caption[List of Jalangi2 functions]{Jalangi2  functions, their descriptions, and their callbacks as stated in the JavaScript Documentation of the analyser}
	\label{tab:jal-fun}
\end{table}

\section{SMT Solver Z3}
\label{sec:z3}

Determining whether a logical expression is satisfiable is difficult as the problem is NP-complete, meaning that as the size and complexity of the expression increase, the number of possible variable assignments grows exponentially. This makes finding a satisfying assignment computationally expensive and challenging, especially when dealing with a large number of variables and constraints~\cite{schaefer_complexity_1978}.

Automating the process of checking  for satisfiability is done by a \textit{Boolean Satisfiability Theories} (SAT) Solver. The development of SAT solvers began with the introduction of the Davis-Putnam algorithm~\citet{davis_computing_1960}, which laid the groundwork for solving Boolean satisfiability problems. This approach was improved by incorporating backtracking techniques, resulting in the DPLL (Davis-Putnam-Logemann-Loveland) algorithm~\citet{davis_machine_1962}. Notable improvements happened with the introduction of the tool \textbf{GRASP}~\cite{silva_grasp_1996}, by adding conflict analysis to the basic backtracking algorithm, allowing non-chronological backtracking in order to solve conflicts. Important advances continued with \textbf{CHAFF}~\citet{moskewicz_chaff_2001}, which employed advanced search strategies to outperform earlier solvers.



To illustrate how the DPLL algorithm operates, consider the following 3-Conjunctive Normal Form (3-CNF) formula: $(a \vee \neg b \vee c) \wedge (\neg a \vee b \vee d) \wedge (\neg c \vee \neg d \vee e)$. The algorithm starts by using pure literal elimination. Among the literals present, the variable $e$ appears only positively, making it a pure literal. Assigning $e = true$ satisfies the third clause and allows it to be removed from further consideration. The formula is then reduced to two clauses: $(a \vee \neg b \vee c)$ and $(\neg a \vee b \vee d)$. At this stage, no additional pure literals or unit clauses are available, so the algorithm proceeds by choosing a variable to assign—let us select $a = true$. This assignment satisfies the first clause. In the second clause, the literal $\neg a$ becomes false, so the clause reduces to $(b \vee d)$, requiring either $b$ or $d$ to be true. Assigning $b = true$ satisfies this clause as well. At this point, all clauses are satisfied, and the algorithm concludes with a successful assignment: $a = true$, $b = true$, and $e = true$, with the remaining variables ($c$ and $d$) left unassigned, as they are not necessary for satisfying the formula - they can be assigned any value (true or false), and the formula will still be satisfied.

As research progressed, the need arose for solvers that could handle more complex logical structures, leading to the emergence of Satisfiability Modulo Theories (SMT) solvers~\cite{shostak_algorithm_1978, boyer_integrating_1988-1}.

The DPLL(T) framework extends the classical DPLL algorithm for propositional satisfiability to handle satisfiability modulo theories (SMT), allowing for reasoning over formulas involving background theories such as linear arithmetic, arrays, and functions. The core idea behind DPLL(T) is to separate the Boolean reasoning from the theory-specific reasoning. Given a formula $\phi$, the SMT solver first constructs a propositional abstraction by replacing theory atoms with propositional variables, which is then processed by a DPLL-based SAT solver. This solver searches for a satisfying assignment to the Boolean abstraction. Whenever a full or partial assignment is found, the corresponding theory literals are handed off to a theory solver (T-solver) to check for consistency within the theory $T$. If the theory solver confirms that the assignment is consistent, then $\phi$ is satisfiable. Otherwise, the theory solver produces a conflict clause — 
a set of literals that cannot be simultaneously satisfied under $T$ - which is communicated back to the SAT solver to refine its search. This architecture combines the strengths of both Boolean SAT solvers and specialized theory solvers in a modular fashion.~\citet{nieuwenhuis_solving_2006}.
Many modern SMT solvers use the DPLL(T) architecture, such as \textbf{Z3}~\cite{de_moura_z3_2008}, \textbf{SMTInterpol}~\cite{hutchison_smtinterpol_2012} or \textbf{cvc5}~\cite{barbosa_cvc5_2022}.



A SMT solver can be used to solve first-order logic, which extends the language of boolean operation by more complex expressions such as functions, predicate symbols and constants. 
For example a SMT Solver could be used for solving the equation system
$$
    (x + 2y + z = 6 )\land
    (2x + 4y + 2z = 12 )\land
    (x + y - z = 2) 
$$

which gets translated into the SMT-LIB language \cite{barrett_smt-lib_2025}
\begin{lstlisting}
(declare-const X Real)
(declare-const Y Real)
(declare-const Z Real)
(assert (= (+ (* 2.0 X) (* 2.0 Y) Z) 6.0))
(assert (= (+ (* 2.0 X) (* 4.0 Y) (* 2.0 Z)) 12.0))
(assert (= (- (+ X Y) Z) 2.0))
(check-sat)
(get-model)
\end{lstlisting}
Executing this script with Z3 results in either \textit{unsat}, when there is no solution, or \textit{sat} and a list of inputs which satisfiy the model. The example is satisfiable with the inputs
\lstinline[language=JavaScript]+sat ( x = 4 ),( y = 0 ), ( z = 2 )+ and 
\lstinline[language=JavaScript]+sat ( x = 2.5 ), ( y = 1 ),( z = 1.5 )+. 


ExpoSE is built using the Z3 SMT Solver \cite{de_moura_z3_2008}. 
To use the SMT Solver, it offers an interface that connects a program in a higher-level language, like Python, Java, C++, or JavaScript, for which Z3 offers a NPM (Node Package Manager) package since 2022. In ExpoSE, however, it is used in combination with the project Z3JavaScript, as, when ExpoSE got developed, there were no native JavaScript bindings available for Z3. 

Z3Javascript is a wrapper for the API of Z3. It generated the JavaScript bindings to be used in ExpoSE, and builds the Z3 binary. It then exposes functions that are used to interact with Z3, converting JavaScript types into C-types. Additionally, it transforms JavaScript regular expressions in order for the Z3 parser to understand them, as Z3 does not support these from the get go. These bindings are required to connect these higher-level languages to the core system of Z3, which is implemented in C.

ExpoSE uses Z3 to solve the path conditions generated by the first run of the symbolic execution, to yield new inputs, which in turn add new path conditions to be solved by Z3. 
A path condition generated from the small function in \autoref{lst:example-program} would be \lstinline[language=JavaScript]+(> value 0.0))+ which in turn is cast into a {\tt{Real}} for Z3
\begin{lstlisting}.
(declare-fun value () Real)
(assert (not (<= value 0.0)))
\end{lstlisting}
This Z3 statement declares the symbolic variable "value" as a function of return type real and asserts that the function returns a real that is greater than zero.  


\section{ExpoSE}
\label{sec:expose}
ExpoSE builds on top of the previously presented projects and technologies. Utilising these aforementioned tools, it is a DSE Framework for JavaScript, which allows almost any JavaScript code to be tested for bugs, by generating tests that cover the code base to a high degree and checking for reachability of statements\cite{loring_expose_2017}

In the following, we will demonstrate how exactly the framework operates, based on the small function \autoref{lst:example-program}, explaining it line by line.
\begin{itemize}
    \item Line 1: \lstinline[language=JavaScript]{const S$ = require("S$")}: S\$ loads the interface library, that allows the user to interact with ExpoSE, declare a variable as symbolic and create assertions of conditions. More on that in the next lines.
    \item Line 3: \lstinline[language=JavaScript]{let x = S$.symbol("value")}: We create a symbolic variable “x” by using the S\$ function “symbol”, which allows us to define a name to track the variable with. We pass the system internal variable name “value” as a parameter.  
    \item Line 4: \lstinline[language=JavaScript]{let y = S$.symbol("multiplier", 2)}: We then create a symbolic variable “y”, internally called “multiplier”, this time, we also assign a starting seed (2), which at the same time defines the type of the variable.
    \item Line 5 to 7: We then apply these variables and try to do something with them. Here, we have a simple condition \lstinline[language=JavaScript]+x > 0+, which, when fulfilled, triggers the assertion \lstinline[language=JavaScript]{S$.assert(x*y > x)}, asserting that the condition is fulfilled. If the condition is violated, this assertion throws the exception "assertion violation". 
\end{itemize}
Afterwards, ExpoSE uses the functions exposed by the Jalangi2 backend  to access the instrumented code. For this, ExpoSE had to implement the callbacks of the provided backend functions. A template for these can be found in the Jalangi2 source code, with explanations for each of the functions, as part of an example analysis program\footnote{https://github.com/Samsung/jalangi2/blob/master/src/js/runtime/analysisCallbackTemplate.js}. 
It starts by registering all local variables, functions and formal parameters, in our example case the variables and constants \lstinline[language=JavaScript]{S$}, \lstinline[language=JavaScript]{x} and \lstinline[language=JavaScript]{y}. Subsequently, it resolves the statements, loads the \lstinline[language=JavaScript]{S$} library and creates a concolic variable: if a concrete value is present, it uses this as starting seed. Otherwise, it will try all primitive types as the first input generation (i.e. string, array, number, object etc). The symbolic part of the concolic wrapper saves all encountered path conditions, which will be used to generate a new input which satisfies another path condition, thereby diverging from the original path, and maybe finding alternative paths.
By having the assertion \lstinline[language=JavaScript]{x*y > x} we force ExpoSE to create two more paths than it normally would. Without the assertion, there are the two paths \lstinline[language=JavaScript]{x>0} and \lstinline[language=JavaScript]{!x>0}. But with the assertion, we added the path condition \lstinline[language=JavaScript]{(x*y) > x} and its negation. This can be used to test for a certain behaviour, but requires manual modification of the program. Similar to normal conditionals, it also leads to an increasing number of explorable paths.



