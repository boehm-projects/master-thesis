
@incollection{barrett_satisfiability_2009,
	title = {Satisfiability modulo theories},
	isbn = {978-1-58603-929-5},
	url = {http://www.scopus.com/inward/record.url?scp=69949133234&partnerID=8YFLogxK},
	series = {Frontiers in Artificial Intelligence and Applications},
	abstract = {Applications in artificial intelligence, formal verification, and other areas have greatly benefited from the recent advances in {SAT}. It is often the case, however, that applications in these fields require determining the satisfiability of formulas in more expressive logics such as first-order logic. Also, these applications typically require not general first-order satisfiability, but rather satisfiability with respect to some background theory, which fixes the interpretations of certain predicate and function symbols. For many background theories, specialized methods yield decision procedures for the satisfiability of quantifier-free formulas or some subclass thereof. Specialized decision procedures have been discovered for a long and still growing list of theories with practical applications. These include the theory of equality, various theories of arithmetic, and certain theories of arrays, as well as theories of lists, tuples, records, and bit-vectors of a fixed or arbitrary finite size. The research field concerned with determining the satisfiability of formulas with respect to some background theory is called Satisfiability Modulo Theories ({SMT}). This chapter provides a brief overview of {SMT} together with references to the relevant literature for a deeper study. It begins with an overview of techniques for solving {SMT} problems by encodings to {SAT}. The rest of the chapter is mostly concerned with an alternative approach in which a {SAT} solver is integrated with a separate decision procedure (called a theory solver) for conjunctions of literals in the background theory. After presenting this approach as a whole, the chapter provides more details on how to construct and combine theory solvers, and discusses several extensions and enhancements.},
	pages = {825--885},
	booktitle = {Handbook of Satisfiability},
	publisher = {{IOS} Press},
	author = {Barrett, Clark and Sebastiani, Roberto and Seshia, Sanjit A. and Tinelli, Cesare},
	urldate = {2025-02-17},
	date = {2009},
	doi = {10.3233/978-1-58603-929-5-825},
}

@inproceedings{csallner_dysy_2008,
	location = {Leipzig, Germany},
	title = {{DySy}: dynamic symbolic execution for invariant inference},
	isbn = {978-1-60558-079-1},
	url = {http://portal.acm.org/citation.cfm?doid=1368088.1368127},
	doi = {10.1145/1368088.1368127},
	shorttitle = {{DySy}},
	abstract = {Dynamically discovering likely program invariants from concrete test executions has emerged as a highly promising software engineering technique. Dynamic invariant inference has the advantage of succinctly summarizing both “expected” program inputs and the subset of program behaviors that is normal under those inputs. In this paper, we introduce a technique that can drastically increase the relevance of inferred invariants, or reduce the size of the test suite required to obtain good invariants. Instead of falsifying invariants produced by pre-set patterns, we determine likely program invariants by combining the concrete execution of actual test cases with a simultaneous symbolic execution of the same tests. The symbolic execution produces abstract conditions over program variables that the concrete tests satisfy during their execution. In this way, we obtain the beneﬁts of dynamic inference tools like Daikon: the inferred invariants correspond to the observed program behaviors. At the same time, however, our inferred invariants are much more suited to the program at hand than Daikon’s hardcoded invariant patterns. The symbolic invariants are literally derived from the program text itself, with appropriate value substitutions as dictated by symbolic execution.},
	eventtitle = {the 13th international conference},
	pages = {281},
	booktitle = {Proceedings of the 13th international conference on Software engineering  - {ICSE} '08},
	publisher = {{ACM} Press},
	author = {Csallner, Christoph and Tillmann, Nikolai and Smaragdakis, Yannis},
	urldate = {2025-02-17},
	date = {2008},
	langid = {english},
}

@inproceedings{elkarablieh_precise_2009,
	location = {Chicago {IL} {USA}},
	title = {Precise pointer reasoning for dynamic test generation},
	isbn = {978-1-60558-338-9},
	url = {https://dl.acm.org/doi/10.1145/1572272.1572288},
	doi = {10.1145/1572272.1572288},
	abstract = {Dynamic test generation consists of executing a program while gathering symbolic constraints on inputs from predicates encountered in branch statements, and of using a constraint solver to infer new program inputs from previous constraints in order to steer next executions towards new program paths. Variants of this technique have recently been adopted in several bug detection tools, including our whitebox fuzzer {SAGE}, which has found dozens of new expensive security-related bugs in many Windows applications and is now routinely used in various Microsoft groups.},
	eventtitle = {{ISSTA} '09: International Symposium on Software Testing and Analysis},
	pages = {129--140},
	booktitle = {Proceedings of the eighteenth international symposium on Software testing and analysis},
	publisher = {{ACM}},
	author = {Elkarablieh, Bassem and Godefroid, Patrice and Levin, Michael Y.},
	urldate = {2025-02-15},
	date = {2009-07-19},
	langid = {english},
}

@article{jhala_software_2009,
	title = {Software model checking},
	volume = {41},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/1592434.1592438},
	doi = {10.1145/1592434.1592438},
	abstract = {We survey recent progress in software model checking.},
	pages = {1--54},
	number = {4},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Jhala, Ranjit and Majumdar, Rupak},
	urldate = {2025-02-15},
	date = {2009-10},
	langid = {english},
}

@inproceedings{coppa_rethinking_2017,
	location = {Urbana, {IL}},
	title = {Rethinking pointer reasoning in symbolic execution},
	isbn = {978-1-5386-2684-9},
	url = {http://ieeexplore.ieee.org/document/8115671/},
	doi = {10.1109/ASE.2017.8115671},
	abstract = {Symbolic execution is a popular program analysis technique that allows seeking for bugs by reasoning over multiple alternative execution states at once. As the number of states to explore may grow exponentially, a symbolic executor may quickly run out of space. For instance, a memory access to a symbolic address may potentially reference the entire address space, leading to a combinatorial explosion of the possible resulting execution states. To cope with this issue, state-of-the-art executors concretize symbolic addresses that span memory intervals larger than some threshold. Unfortunately, this could result in missing interesting execution states, e.g., where a bug arises.},
	eventtitle = {2017 32nd {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
	pages = {613--618},
	booktitle = {2017 32nd {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
	publisher = {{IEEE}},
	author = {Coppa, Emilio and D'Elia, Daniele Cono and Demetrescu, Camil},
	urldate = {2025-02-15},
	date = {2017-10},
	langid = {english},
}

@article{cadar_symbolic_2013,
	title = {Symbolic execution for software testing: three decades later},
	volume = {56},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/2408776.2408795},
	doi = {10.1145/2408776.2408795},
	shorttitle = {Symbolic execution for software testing},
	abstract = {The challenges---and great promise---of modern symbolic execution techniques, and the tools to help implement them.},
	pages = {82--90},
	number = {2},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Cadar, Cristian and Sen, Koushik},
	urldate = {2025-02-15},
	date = {2013-02},
	langid = {english},
}

@article{godefroid_dart_nodate,
	title = {{DART}: Directed Automated Random Testing},
	abstract = {We present a new tool, named {DART}, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. Together, these three techniques constitute Directed Automated Random Testing, or {DART} for short. The main strength of {DART} is thus that testing can be performed completely automatically on any program that compiles – there is no need to write any test driver or harness code. During testing, {DART} detects standard errors such as program crashes, assertion violations, and non-termination. Preliminary experiments to unit test several examples of C programs are very encouraging.},
	author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
	langid = {english},
}

@inproceedings{godefroid_random_2007,
	location = {Atlanta Georgia},
	title = {Random testing for security: blackbox vs. whitebox fuzzing},
	isbn = {978-1-59593-881-7},
	url = {https://dl.acm.org/doi/10.1145/1292414.1292416},
	doi = {10.1145/1292414.1292416},
	shorttitle = {Random testing for security},
	abstract = {Fuzz testing is an eﬀective technique for ﬁnding security vulnerabilities in software. Fuzz testing is a form of blackbox random testing which randomly mutates well-formed inputs and tests the program on the resulting data. In some cases, grammars are used to randomly generate the well-formed inputs. This also allows the tester to encode applicationspeciﬁc knowledge (such as corner cases of particular interest) as part of the grammar, and to specify test heuristics by assigning probabilistic weights to production rules. Although fuzz testing can be remarkably eﬀective, the limitations of blackbox random testing are well-known. For instance, the then branch of the conditional statement “if (x==10) then” has only one in 232 chances of being exercised if x is a randomly chosen 32-bit input value. This intuitively explains why random testing usually provides low code coverage.},
	eventtitle = {{ASE}07: International Conference on Automated Software Engineering 2007},
	pages = {1--1},
	booktitle = {Proceedings of the 2nd international workshop on Random testing: co-located with the 22nd {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE} 2007)},
	publisher = {{ACM}},
	author = {Godefroid, Patrice},
	urldate = {2025-02-15},
	date = {2007-11-06},
	langid = {english},
}

@article{demott_evolving_nodate,
	title = {The Evolving Art of Fuzzing},
	author = {{DeMott}, Jared},
	langid = {english},
}

@article{b_w_boehm_verifying_1984,
	title = {Verifying and Validating Software Requirements and Design Specifications},
	volume = {1},
	doi = {10.1109/MS.1984.233702},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the {ProQuest} Platform.},
	pages = {75--88},
	number = {1},
	author = {{B. W. Boehm}},
	urldate = {2025-02-13},
	date = {1984},
}

@article{boehm_software_nodate,
	title = {Software Engineering Economics},
	abstract = {This paper summarizes the current state of the art and recent trends in software engineering economics. It provides an overview of economic analysis techniques and their applicability to software engineering and management. It surveys the field of software cost estimation, including the major estimation techniques available, the state of the art in algorithmic cost models, and the outstanding research issues in software cost estimation.},
	journaltitle = {Prentice Hall},
	author = {Boehm, Barry W},
	langid = {english},
}

@online{roy_t_fielding_rest_2008,
	title = {{REST} {APIs} must be hypertext-driven » Untangled https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven},
	url = {https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven},
	shorttitle = {{REST} {APIs} must be hypertext-driven » Untangled https},
	author = {{Roy T. Fielding}},
	urldate = {2025-02-12},
	date = {2008},
}

@report{berners-lee_uniform_2005,
	title = {Uniform Resource Identifier ({URI}): Generic Syntax},
	url = {https://datatracker.ietf.org/doc/rfc3986},
	shorttitle = {Uniform Resource Identifier ({URI})},
	abstract = {A Uniform Resource Identifier ({URI}) is a compact sequence of characters that identifies an abstract or physical resource. This specification defines the generic {URI} syntax and a process for resolving {URI} references that might be in relative form, along with guidelines and security considerations for the use of {URIs} on the Internet. The {URI} syntax defines a grammar that is a superset of all valid {URIs}, allowing an implementation to parse the common components of a {URI} reference without knowing the scheme-specific requirements of every possible identifier. This specification does not define a generative grammar for {URIs}; that task is performed by the individual specifications of each {URI} scheme. [{STANDARDS}-{TRACK}]},
	number = {{RFC} 3986},
	institution = {Internet Engineering Task Force},
	type = {Request for Comments},
	author = {Berners-Lee, Tim and Fielding, Roy T. and Masinter, Larry M.},
	urldate = {2025-02-12},
	date = {2005-01},
	doi = {10.17487/RFC3986},
	note = {Num Pages: 61},
}

@online{noauthor_jsonapi_nodate,
	title = {{JSON}:{API} — Latest Specification (v1.1) https://jsonapi.org/format/},
	url = {https://jsonapi.org/format/},
	urldate = {2025-02-12},
}

@online{noauthor_serverless_nodate,
	title = {Serverless Function, {FaaS} Serverless - {AWS} Lambda - {AWS}},
	url = {https://aws.amazon.com/lambda/},
	abstract = {{AWS} Lambda is a serverless compute service for running code without having to provision or manage servers. You pay only for the compute time you consume.},
	titleaddon = {Amazon Web Services, Inc.},
	urldate = {2025-02-12},
	langid = {american},
}

@report{fielding_http_2022,
	title = {{HTTP} Semantics},
	url = {https://datatracker.ietf.org/doc/rfc9110},
	abstract = {The Hypertext Transfer Protocol ({HTTP}) is a stateless application-level protocol for distributed, collaborative, hypertext information systems. This document describes the overall architecture of {HTTP}, establishes common terminology, and defines aspects of the protocol that are shared by all versions. In this definition are core protocol elements, extensibility mechanisms, and the "http" and "https" Uniform Resource Identifier ({URI}) schemes. This document updates {RFC} 3864 and obsoletes {RFCs} 2818, 7231, 7232, 7233, 7235, 7538, 7615, 7694, and portions of 7230.},
	number = {{RFC} 9110},
	institution = {Internet Engineering Task Force},
	type = {Request for Comments},
	author = {Fielding, Roy T. and Nottingham, Mark and Reschke, Julian},
	urldate = {2025-02-12},
	date = {2022-06},
	doi = {10.17487/RFC9110},
	note = {Num Pages: 194},
}

@article{oehlert_violating_2005,
	title = {Violating assumptions with fuzzing},
	volume = {3},
	issn = {1558-4046},
	url = {https://ieeexplore.ieee.org/document/1423963/?arnumber=1423963},
	doi = {10.1109/MSP.2005.55},
	abstract = {Fuzzing is a highly automated testing technique that covers numerous boundary cases using invalid data (from files, network protocols, {API} calls, and other targets) as application input to better ensure the absence of exploitable vulnerabilities. Fuzzing lets developers or quality assurance ({QA}) teams test large numbers of boundary cases when doing so with techniques such as functional testing would be cost prohibitive. Comprehensive negative test cases - those that verify that a product does not do something it shouldn't do, rather than that it does something it is supposed to (positive test cases) - are difficult to construct because the number of possible permutations is astronomical. Yet, fuzzing covers a significant portion of negative test cases without forcing the tester to deal with each specific test case for a given boundary condition.},
	pages = {58--62},
	number = {2},
	journaltitle = {{IEEE} Security \& Privacy},
	author = {Oehlert, P.},
	urldate = {2025-02-12},
	date = {2005-03},
	note = {Conference Name: {IEEE} Security \& Privacy},
	keywords = {Application software, Automatic testing, Computer security, Cost function, Data privacy, Data security, Kernel, Network interfaces, Protocols, Quality assurance, boundary conditions, completeness testing, comprehensive negative testing, fuzzing, quality assurance, software testing},
}

@article{liang_fuzzing_2018,
	title = {Fuzzing: State of the Art},
	volume = {67},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0018-9529, 1558-1721},
	url = {https://ieeexplore.ieee.org/document/8371326/},
	doi = {10.1109/TR.2018.2834476},
	shorttitle = {Fuzzing},
	abstract = {As one of the most popular software testing techniques, fuzzing can ﬁnd a variety of weaknesses in a program, such as software bugs and vulnerabilities, by generating numerous test inputs. Due to its effectiveness, fuzzing is regarded as a valuable bug hunting method. In this paper, we present an overview of fuzzing that concentrates on its general process, as well as classiﬁcations, followed by detailed discussion of the key obstacles and some stateof-the-art technologies which aim to overcome or mitigate these obstacles. We further investigate and classify several widely used fuzzing tools. Our primary goal is to equip the stakeholder with a better understanding of fuzzing and the potential solutions for improving fuzzing methods in the spectrum of software testing and security. To inspire future research, we also predict some future directions with regard to fuzzing.},
	pages = {1199--1218},
	number = {3},
	journaltitle = {{IEEE} Transactions on Reliability},
	shortjournal = {{IEEE} Trans. Rel.},
	author = {Liang, Hongliang and Pei, Xiaoxiao and Jia, Xiaodong and Shen, Wuwei and Zhang, Jian},
	urldate = {2025-02-12},
	date = {2018-09},
	langid = {english},
}

@online{noauthor_web_2012,
	title = {The Web Application Security Consortium},
	url = {http://projects.webappsec.org/w/page/13246967/The%20Web%20Security%20Glossary#WebApplication},
	shorttitle = {{WASC}},
	titleaddon = {The Web Security Glossary},
	urldate = {2025-02-07},
	date = {2012},
}

@inproceedings{fong_web_2007,
	location = {Waikoloa, {HI}, {USA}},
	title = {Web Application Scanners: Definitions and Functions},
	url = {http://ieeexplore.ieee.org/document/4076950/},
	doi = {10.1109/HICSS.2007.611},
	shorttitle = {Web Application Scanners},
	abstract = {There are many commercial software security assurance tools that claim to detect and prevent vulnerabilities in application software. However, a closer look at the tools often leaves one wondering which tools find what vulnerabilities. This paper identifies a taxonomy of software security assurance tools and defines one type of tool: web application scanner, i.e., an automated program that examines web applications for security vulnerabilities. We describe the types of functions that are generally found in a web application scanner and how to test it.},
	eventtitle = {2007 40th Annual Hawaii International Conference on System Sciences ({HICSS}'07)},
	pages = {280b--280b},
	booktitle = {2007 40th Annual Hawaii International Conference on System Sciences ({HICSS}'07)},
	publisher = {{IEEE}},
	author = {Fong, Elizabeth and Okun, Vadim},
	urldate = {2025-02-07},
	date = {2007},
	langid = {english},
}

@article{veres_exploration_nodate,
	title = {An Exploration of Current Techniques in {OWASP} Vulnerability Detection and Improvement Opportunities},
	abstract = {Web applications are foundational in today’s digital landscape, necessitating advanced security measures. This study delves into Interactive Application Security Testing ({IAST}) and Web Fuzzing, two pivotal techniques for detecting web vulnerabilities. We systematically evaluate their strengths and weaknesses, emphasizing their potential in addressing vulnerabilities highlighted by the {OWASP} Top 10. While {IAST} excels in real-time vulnerability detection, Web Fuzzing offers an expansive approach, adept at uncovering elusive edge cases. Our research suggests that combining these techniques could lead to substantial enhancements in web application security. Additionally, we introduce the idea of an open-source {IAST} tool and contemplate the benefits that recent advances in artificial intelligence might bring to these techniques. Furthermore, we underscore the significance of understanding these tools’ operation within the realm of cloud computing.},
	author = {Veres, Andrei-Claudiu},
	langid = {english},
}

@article{cadar_klee_nodate,
	title = {{KLEE}: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs},
	abstract = {We present a new symbolic execution tool, {KLEE}, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used {KLEE} to thoroughly check all 89 stand-alone programs in the {GNU} {COREUTILS} utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. {KLEE}-generated tests achieve high line coverage — on average over 90\% per tool (median: over 94\%) — and signiﬁcantly beat the coverage of the developers’ own hand-written test suite. When we did the same for 75 equivalent tools in the {BUSYBOX} embedded system suite, results were even better, including 100\% coverage on 31 of them.},
	author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
	langid = {english},
}

@inproceedings{sen_concolic_2007,
	location = {New York, {NY}, {USA}},
	title = {Concolic testing},
	isbn = {978-1-59593-882-4},
	url = {https://doi.org/10.1145/1321631.1321746},
	doi = {10.1145/1321631.1321746},
	series = {{ASE} '07},
	abstract = {Concolic testing automates test input generation by combining the concrete and symbolic (concolic) execution of the code under test. Traditional test input generation techniques use either (1) concrete execution or (2) symbolic execution that builds constraints and is followed by a generation of concrete test inputs from these constraints. In contrast, concolic testing tightly couples both concrete and symbolic executions: they run simultaneously, and each gets feedback from the other.We have implemented concolic testing in tools for testing both C and Java programs. We have used the tools to find bugs in several real-world software systems including {SGLIB}, a popular C data structure library used in a commercial tool, a third-party implementation of the Needham-Schroeder protocol and the {TMN} protocol, the scheduler of Honeywell's {DEOS} real-time operating system, and the Sun Microsystems' {JDK} 1.4 collection framework. In this tutorial, we will describe concolic testing and some of its recent extensions},
	pages = {571--572},
	booktitle = {Proceedings of the 22nd {IEEE}/{ACM} International Conference on Automated Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Sen, Koushik},
	urldate = {2025-01-29},
	date = {2007-11-05},
}

@article{pak_hybrid_nodate,
	title = {Hybrid Fuzz Testing: Discovering Software Bugs via Fuzzing and Symbolic Execution},
	author = {Pak, Brian S},
	langid = {english},
}

@online{noauthor_httpswwwusenixorgsystemfilesconferenceusenixsecurity15sec15-paper-ramospdf_nodate,
	title = {https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-ramos.pdf},
	url = {https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-ramos.pdf},
	urldate = {2025-01-24},
}

@article{ramos_under-constrained_nodate,
	title = {Under-Constrained Symbolic Execution: Correctness Checking for Real Code},
	abstract = {Software bugs are a well-known source of security vulnerabilities. One technique for ﬁnding bugs, symbolic execution, considers all possible inputs to a program but suffers from scalability limitations. This paper uses a variant, under-constrained symbolic execution, that improves scalability by directly checking individual functions, rather than whole programs. We present {UC}-{KLEE}, a novel, scalable framework for checking C/C++ systems code, along with two use cases. First, we use {UC}-{KLEE} to check whether patches introduce crashes. We check over 800 patches from {BIND} and {OpenSSL} and ﬁnd 12 bugs, including two {OpenSSL} denial-of-service vulnerabilities. We also verify (with caveats) that 115 patches do not introduce crashes. Second, we use {UC}-{KLEE} as a generalized checking framework and implement checkers to ﬁnd memory leaks, uninitialized data, and unsafe user input. We evaluate the checkers on over 20,000 functions from {BIND}, {OpenSSL}, and the Linux kernel, ﬁnd 67 bugs, and verify that hundreds of functions are leak free and that thousands of functions do not access uninitialized data.},
	author = {Ramos, David A and Engler, Dawson},
	langid = {english},
}

@article{tillmann_unit_2006,
	title = {Unit tests reloaded: parameterized unit testing with symbolic execution},
	volume = {23},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0740-7459},
	url = {http://ieeexplore.ieee.org/document/1657937/},
	doi = {10.1109/MS.2006.117},
	shorttitle = {Unit tests reloaded},
	pages = {38--47},
	number = {4},
	journaltitle = {{IEEE} Software},
	shortjournal = {{IEEE} Softw.},
	author = {Tillmann, N. and Schulte, W.},
	urldate = {2025-01-19},
	date = {2006-07},
	langid = {english},
}

@article{loring_practical_nodate,
	title = {Practical Dynamic Symbolic Execution for {JavaScript}},
	author = {Loring, Blake William},
	langid = {english},
}

@inproceedings{cha_unleashing_2012,
	location = {San Francisco, {CA}, {USA}},
	title = {Unleashing Mayhem on Binary Code},
	isbn = {978-1-4673-1244-8 978-0-7695-4681-0},
	url = {https://ieeexplore.ieee.org/document/6234425/},
	doi = {10.1109/SP.2012.31},
	abstract = {In this paper we present {MAYHEM}, a new system for automatically ﬁnding exploitable bugs in binary (i.e., executable) programs. Every bug reported by {MAYHEM} is accompanied by a working shell-spawning exploit. The working exploits ensure soundness and that each bug report is securitycritical and actionable. {MAYHEM} works on raw binary code without debugging information. To make exploit generation possible at the binary-level, {MAYHEM} addresses two major technical challenges: actively managing execution paths without exhausting memory, and reasoning about symbolic memory indices, where a load or a store address depends on user input. To this end, we propose two novel techniques: 1) hybrid symbolic execution for combining online and ofﬂine (concolic) execution to maximize the beneﬁts of both techniques, and 2) index-based memory modeling, a technique that allows {MAYHEM} to efﬁciently reason about symbolic memory at the binary level. We used {MAYHEM} to ﬁnd and demonstrate 29 exploitable vulnerabilities in both Linux and Windows programs, 2 of which were previously undocumented.},
	eventtitle = {2012 {IEEE} Symposium on Security and Privacy ({SP}) Conference dates subject to change},
	pages = {380--394},
	booktitle = {2012 {IEEE} Symposium on Security and Privacy},
	publisher = {{IEEE}},
	author = {Cha, Sang Kil and Avgerinos, Thanassis and Rebert, Alexandre and Brumley, David},
	urldate = {2025-01-09},
	date = {2012-05},
	langid = {english},
}

@online{noauthor_httpsusersececmueduaavgerinpapersmayhem-oakland-12pdf_nodate,
	title = {https://users.ece.cmu.edu/{\textasciitilde}aavgerin/papers/mayhem-oakland-12.pdf},
	url = {https://users.ece.cmu.edu/~aavgerin/papers/mayhem-oakland-12.pdf},
	urldate = {2025-01-09},
}

@article{aydos_security_2022,
	title = {Security testing of web applications: A systematic mapping of the literature},
	volume = {34},
	issn = {1319-1578},
	url = {https://www.sciencedirect.com/science/article/pii/S131915782100269X},
	doi = {10.1016/j.jksuci.2021.09.018},
	shorttitle = {Security testing of web applications},
	abstract = {Context
Web application security is a main component of any web-based business. Web applications are subject to attacks from different locations at various levels of scale and complexity. In this context, a large number of testing techniques, tools and frameworks have been proposed by both practitioners and researchers to effectively and efficiently test the security of web applications.
Objective
As the number of papers increases in the security of web applications and this research area matures, reviewing and getting an overview of this area is getting challenging for a practitioner or a new researcher. Our objective is to summarize the state-of-the-art in web application security testing which could benefit practitioners to potentially utilize that information.
Method
We review and structure the body of knowledge related to web application security testing in the form of a systematic literature mapping ({SLM}). As part of this study, we pose four sets of research questions, define selection and exclusion criteria, and systematically develop and refine a classification schema. The initial pool consisted of 154 articles. Systematic voting was conducted among the authors regarding the inclusion/exclusion of articles. As a result, there were 80 technical articles in our final pool. Accordance with our inclusion and exclusion criteria, the first article was published in 2005 and this review includes all the papers until the end of 2020. During December 2020, January and February 2021, the search phase has been conducted.
Results
This review paper provides an overview of web application security testing with different focused headings. These headings cover contribution types, web security testing tools and their sub features, specific questions/features to the security testing such as vulnerability types, system under testing ({SUT}) focused headings and more.
Conclusion
The results of this study would benefit researchers working on web application security testing. Also, it could be useful for developers who discuss application security while they develop web applications. Thanks to this paper, these researchers could utilize the all results and use them to catch the trend of web application security testing and secure development.},
	pages = {6775--6792},
	number = {9},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	shortjournal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Aydos, Murat and Aldan, Çiğdem and Coşkun, Evren and Soydan, Alperen},
	urldate = {2024-11-11},
	date = {2022-10-01},
	keywords = {Security testing, Systematic literature mapping, Systematic literature review, Systematic mapping, Web application security},
}

@article{jaiswal_security_2014,
	title = {Security Testing of Web Applications: Issues and Challenges},
	volume = {88},
	issn = {09758887},
	url = {http://research.ijcaonline.org/volume88/number3/pxc3893667.pdf},
	doi = {10.5120/15334-3667},
	shorttitle = {Security Testing of Web Applications},
	abstract = {Due to the increasing complexity of web systems, security testing has become indispensable and critical activity of web application development life cycle. Security testing aims to maintain the confidentiality of the data, to check against any information leakage and to maintain the functionality as intended. It checks whether the security requirements are fulfilled by the web applications when they are subjected to malicious input data. Due to the rising explosion in the security vulnerabilities, there occurs a need to understand its unique challenges and issues which will eventually serve as a useful input for the security testing tool developers and test managers for their relative projects.},
	pages = {26--32},
	number = {3},
	journaltitle = {International Journal of Computer Applications},
	shortjournal = {{IJCA}},
	author = {Jaiswal, Arunima and Raj, Gaurav and Singh, Dheerendra},
	urldate = {2024-11-11},
	date = {2014-02-14},
	langid = {english},
}

@inproceedings{loring_expose_2017,
	location = {New York, {NY}, {USA}},
	title = {{ExpoSE}: practical symbolic execution of standalone {JavaScript}},
	isbn = {978-1-4503-5077-8},
	url = {https://doi.org/10.1145/3092282.3092295},
	doi = {10.1145/3092282.3092295},
	series = {{SPIN} 2017},
	shorttitle = {{ExpoSE}},
	abstract = {{JavaScript} has evolved into a versatile ecosystem for not just the web, but also a wide range of server-side and client-side applications. With this increased scope, the potential impact of bugs increases. We introduce {ExpoSE}, a dynamic symbolic execution engine for Node.js applications. {ExpoSE} automatically generates test cases to find bugs and cover as many paths in the target program as possible. We discuss the specific challenges for symbolic execution arising from the widespread use of regular expressions in such applications. In particular, we make explicit the issues of capture groups, backreferences, and greediness in {JavaScript}'s flavor of regular expressions, and our models improve over previous work that only partially addressed these. We evaluate {ExpoSE} on three popular {JavaScript} libraries that make heavy use of regular expressions, and we report a previously unknown bug in the Minimist library.},
	pages = {196--199},
	booktitle = {Proceedings of the 24th {ACM} {SIGSOFT} International {SPIN} Symposium on Model Checking of Software},
	publisher = {Association for Computing Machinery},
	author = {Loring, Blake and Mitchell, Duncan and Kinder, Johannes},
	urldate = {2024-10-28},
	date = {2017-07-13},
}

@inproceedings{eriksson_black_2021,
	title = {Black Widow: Blackbox Data-driven Web Scanning},
	url = {https://ieeexplore.ieee.org/abstract/document/9519452},
	doi = {10.1109/SP40001.2021.00022},
	shorttitle = {Black Widow},
	abstract = {Modern web applications are an integral part of our digital lives. As we put more trust in web applications, the need for security increases. At the same time, detecting vulnerabilities in web applications has become increasingly hard, due to the complexity, dynamism, and reliance on third-party components. Blackbox vulnerability scanning is especially challenging because (i) for deep penetration of web applications scanners need to exercise such browsing behavior as user interaction and asynchrony, and (ii) for detection of nontrivial injection attacks, such as stored cross-site scripting ({XSS}), scanners need to discover inter-page data dependencies.This paper illuminates key challenges for crawling and scanning the modern web. Based on these challenges we identify three core pillars for deep crawling and scanning: navigation modeling, traversing, and tracking inter-state dependencies. While prior efforts are largely limited to the separate pillars, we suggest an approach that leverages all three. We develop Black Widow, a blackbox data-driven approach to web crawling and scanning. We demonstrate the effectiveness of the crawling by code coverage improvements ranging from 63\% to 280\% compared to other crawlers across all applications. Further, we demonstrate the effectiveness of the web vulnerability scanning by featuring no false positives and finding more cross-site scripting vulnerabilities than previous methods. In older applications, used in previous research, we find vulnerabilities that the other methods miss. We also find new vulnerabili-ties in production software, including {HotCRP}, {osCommerce}, {PrestaShop} and {WordPress}.},
	eventtitle = {2021 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {1125--1142},
	booktitle = {2021 {IEEE} Symposium on Security and Privacy ({SP})},
	author = {Eriksson, Benjamin and Pellegrino, Giancarlo and Sabelfeld, Andrei},
	urldate = {2024-10-28},
	date = {2021-05},
	note = {{ISSN}: 2375-1207},
	keywords = {Crawlers, Cross-site scripting, Distance measurement, Navigation, Privacy, Production, Software, {XSS}, cross-site scripting, security testing, web application scanning, web crawling},
}

@inproceedings{loring_sound_2019,
	location = {New York, {NY}, {USA}},
	title = {Sound regular expression semantics for dynamic symbolic execution of {JavaScript}},
	isbn = {978-1-4503-6712-7},
	url = {https://doi.org/10.1145/3314221.3314645},
	doi = {10.1145/3314221.3314645},
	series = {{PLDI} 2019},
	abstract = {Support for regular expressions in symbolic execution-based tools for test generation and bug finding is insufficient. Common aspects of mainstream regular expression engines, such as backreferences or greedy matching, are ignored or imprecisely approximated, leading to poor test coverage or missed bugs. In this paper, we present a model for the complete regular expression language of {ECMAScript} 2015 ({ES}6), which is sound for dynamic symbolic execution of the test and exec functions. We model regular expression operations using string constraints and classical regular expressions and use a refinement scheme to address the problem of matching precedence and greediness. We implemented our model in {ExpoSE}, a dynamic symbolic execution engine for {JavaScript}, and evaluated it on over 1,000 Node.js packages containing regular expressions, demonstrating that the strategy is effective and can significantly increase the number of successful regular expression queries and therefore boost coverage.},
	pages = {425--438},
	booktitle = {Proceedings of the 40th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {Association for Computing Machinery},
	author = {Loring, Blake and Mitchell, Duncan and Kinder, Johannes},
	urldate = {2024-10-28},
	date = {2019-06-08},
}

@inproceedings{eriksson_black_2023,
	location = {New York, {NY}, {USA}},
	title = {Black Ostrich: Web Application Scanning with String Solvers},
	isbn = {9798400700507},
	url = {https://dl.acm.org/doi/10.1145/3576915.3616582},
	doi = {10.1145/3576915.3616582},
	series = {{CCS} '23},
	shorttitle = {Black Ostrich},
	abstract = {Securing web applications remains a pressing challenge. Unfortunately, the state of the art in web crawling and security scanning still falls short of deep crawling. A major roadblock is the crawlers' limited ability to pass input validation checks when web applications require data of a certain format, such as email, phone number, or zip code. This paper develops Black Ostrich, a principled approach to deep web crawling and scanning. The key idea is to equip web crawling with string constraint solving capabilities to dynamically infer suitable inputs from regular expression patterns in web applications and thereby pass input validation checks. To enable this use of constraint solvers, we develop new automata-based techniques to process {JavaScript} regular expressions. We implement our approach extending and combining the Ostrich constraint solver with the Black Widow web crawler. We evaluate Black Ostrich on a set of 8,820 unique validation patterns gathered from over 21,667,978 forms from a combination of the July 2021 Common{\textasciitilde}Crawl and Tranco top 100K. For these forms and reconstructions of input elements corresponding to the patterns, we demonstrate that Black Ostrich achieves a 99\% coverage of the form validations compared to an average of 36\% for the state-of-the-art scanners. Moreover, out of the 66,377 domains using these patterns, we solve all patterns on 66,309 (99\%) while the combined efforts of the other scanners cover 52,632 (79\%). We further show that our approach can boost coverage by evaluating it on three open-source applications. Our empirical studies include a study of email validation patterns, where we find that 213 (26\%) out of the 825 found email validation patterns liberally admit {XSS} injection payloads.},
	pages = {549--563},
	booktitle = {Proceedings of the 2023 {ACM} {SIGSAC} Conference on Computer and Communications Security},
	publisher = {Association for Computing Machinery},
	author = {Eriksson, Benjamin and Stjerna, Amanda and De Masellis, Riccardo and Rüemmer, Philipp and Sabelfeld, Andrei},
	urldate = {2024-10-28},
	date = {2023-11-21},
}
